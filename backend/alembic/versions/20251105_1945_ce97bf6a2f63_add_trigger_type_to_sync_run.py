"""add trigger_type to sync_run

Revision ID: ce97bf6a2f63
Revises: 192589d734ff
Create Date: 2025-11-05 19:45:09.577113

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'ce97bf6a2f63'
down_revision = '192589d734ff'
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('activity_mappings', 'zammad_type_name',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('activity_mappings', 'kimai_activity_name',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('activity_mappings', 'is_active',
               existing_type=sa.BOOLEAN(),
               nullable=False)
    op.alter_column('activity_mappings', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('activity_mappings', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.add_column('audit_logs', sa.Column('user', sa.String(length=100), nullable=True))
    op.alter_column('audit_logs', 'entity_type',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('audit_logs', 'entity_id',
               existing_type=sa.VARCHAR(),
               type_=sa.Integer(),
               existing_nullable=True,
               postgresql_using='entity_id::integer')
    op.alter_column('audit_logs', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.create_index('idx_audit_logs_action', 'audit_logs', ['action'], unique=False)
    op.create_index('idx_audit_logs_created_at_desc', 'audit_logs', [sa.text('created_at DESC')], unique=False)
    op.drop_constraint('audit_logs_sync_run_id_fkey', 'audit_logs', type_='foreignkey')
    op.drop_column('audit_logs', 'error_message')
    op.drop_column('audit_logs', 'created_by')
    op.drop_column('audit_logs', 'status')
    op.drop_column('audit_logs', 'sync_run_id')
    op.alter_column('connectors', 'api_token',
               existing_type=sa.VARCHAR(),
               type_=sa.Text(),
               existing_nullable=False)
    op.alter_column('connectors', 'is_active',
               existing_type=sa.BOOLEAN(),
               nullable=False)
    op.alter_column('connectors', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('connectors', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.create_index(op.f('ix_connectors_type'), 'connectors', ['type'], unique=False)
    op.add_column('sync_runs', sa.Column('trigger_type', sa.String(length=50), nullable=False))
    op.add_column('sync_runs', sa.Column('start_time', sa.DateTime(timezone=True), nullable=False))
    op.add_column('sync_runs', sa.Column('end_time', sa.DateTime(timezone=True), nullable=True))
    op.add_column('sync_runs', sa.Column('conflicts_detected', sa.Integer(), nullable=False))
    op.alter_column('sync_runs', 'entries_fetched',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('sync_runs', 'entries_synced',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('sync_runs', 'entries_failed',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('sync_runs', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_column('sync_runs', 'started_at')
    op.drop_column('sync_runs', 'completed_at')
    op.add_column('time_entries', sa.Column('connector_id', sa.Integer(), nullable=False))
    op.add_column('time_entries', sa.Column('user_id', sa.Integer(), nullable=True))
    op.add_column('time_entries', sa.Column('synced_to_kimai', sa.Boolean(), nullable=False))
    op.add_column('time_entries', sa.Column('sync_error', sa.Text(), nullable=True))
    op.add_column('time_entries', sa.Column('tags', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column('time_entries', sa.Column('extra_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column('time_entries', sa.Column('synced_at', sa.DateTime(timezone=True), nullable=True))
    op.alter_column('time_entries', 'time_minutes',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               type_=sa.Numeric(precision=10, scale=2),
               existing_nullable=False)
    op.alter_column('time_entries', 'sync_status',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.alter_column('time_entries', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('time_entries', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_constraint('uq_source_source_id', 'time_entries', type_='unique')
    op.create_index('idx_time_entries_entry_date', 'time_entries', ['entry_date'], unique=False)
    op.create_index('idx_time_entries_source_source_id', 'time_entries', ['source', 'source_id'], unique=True)
    op.create_index('idx_time_entries_sync_status', 'time_entries', ['sync_status'], unique=False)
    op.create_index(op.f('ix_time_entries_ticket_number'), 'time_entries', ['ticket_number'], unique=False)
    op.create_foreign_key(None, 'time_entries', 'connectors', ['connector_id'], ['id'])
    op.drop_column('time_entries', 'last_sync_at')
    op.alter_column('users', 'is_active',
               existing_type=sa.BOOLEAN(),
               nullable=False)
    op.drop_index('ix_users_email', table_name='users')
    op.create_unique_constraint(None, 'users', ['email'])
    op.drop_column('users', 'updated_at')
    op.drop_column('users', 'created_at')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('users', sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=False))
    op.add_column('users', sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=False))
    op.drop_constraint(None, 'users', type_='unique')
    op.create_index('ix_users_email', 'users', ['email'], unique=False)
    op.alter_column('users', 'is_active',
               existing_type=sa.BOOLEAN(),
               nullable=True)
    op.add_column('time_entries', sa.Column('last_sync_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'time_entries', type_='foreignkey')
    op.drop_index(op.f('ix_time_entries_ticket_number'), table_name='time_entries')
    op.drop_index('idx_time_entries_sync_status', table_name='time_entries')
    op.drop_index('idx_time_entries_source_source_id', table_name='time_entries')
    op.drop_index('idx_time_entries_entry_date', table_name='time_entries')
    op.create_unique_constraint('uq_source_source_id', 'time_entries', ['source', 'source_id'])
    op.alter_column('time_entries', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('time_entries', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('time_entries', 'sync_status',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('time_entries', 'time_minutes',
               existing_type=sa.Numeric(precision=10, scale=2),
               type_=sa.DOUBLE_PRECISION(precision=53),
               existing_nullable=False)
    op.drop_column('time_entries', 'synced_at')
    op.drop_column('time_entries', 'extra_metadata')
    op.drop_column('time_entries', 'tags')
    op.drop_column('time_entries', 'sync_error')
    op.drop_column('time_entries', 'synced_to_kimai')
    op.drop_column('time_entries', 'user_id')
    op.drop_column('time_entries', 'connector_id')
    op.add_column('sync_runs', sa.Column('completed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('sync_runs', sa.Column('started_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.alter_column('sync_runs', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('sync_runs', 'entries_failed',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('sync_runs', 'entries_synced',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('sync_runs', 'entries_fetched',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.drop_column('sync_runs', 'conflicts_detected')
    op.drop_column('sync_runs', 'end_time')
    op.drop_column('sync_runs', 'start_time')
    op.drop_column('sync_runs', 'trigger_type')
    op.drop_index(op.f('ix_connectors_type'), table_name='connectors')
    op.alter_column('connectors', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('connectors', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('connectors', 'is_active',
               existing_type=sa.BOOLEAN(),
               nullable=True)
    op.alter_column('connectors', 'api_token',
               existing_type=sa.Text(),
               type_=sa.VARCHAR(),
               existing_nullable=False)
    op.add_column('audit_logs', sa.Column('sync_run_id', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('audit_logs', sa.Column('status', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('audit_logs', sa.Column('created_by', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('audit_logs', sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True))
    op.create_foreign_key('audit_logs_sync_run_id_fkey', 'audit_logs', 'sync_runs', ['sync_run_id'], ['id'])
    op.drop_index('idx_audit_logs_created_at_desc', table_name='audit_logs')
    op.drop_index('idx_audit_logs_action', table_name='audit_logs')
    op.alter_column('audit_logs', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('audit_logs', 'entity_id',
               existing_type=sa.Integer(),
               type_=sa.VARCHAR(),
               existing_nullable=True)
    op.alter_column('audit_logs', 'entity_type',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.drop_column('audit_logs', 'user')
    op.alter_column('activity_mappings', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('activity_mappings', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('activity_mappings', 'is_active',
               existing_type=sa.BOOLEAN(),
               nullable=True)
    op.alter_column('activity_mappings', 'kimai_activity_name',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.alter_column('activity_mappings', 'zammad_type_name',
               existing_type=sa.VARCHAR(),
               nullable=False)
    # ### end Alembic commands ###
